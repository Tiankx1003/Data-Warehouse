# 一、数据仓库概念

**数据仓库 Data-HouseWare**是为企业==所有决策==制定过程，提供==所有==系统数据支持的==战略==集合。

通过对数据仓库中数据的分析，可以帮助企业，**改进业务流程、控制成本、提高产品质量**等。

数据仓库并不是数据的最终目的地，而是为数据UI中的目的地做好准备。这些准备包括对数据的**清洗、转义、分类、重组、合并、拆分、统计**等等

通过**日志采集系统、业务系统数据库、爬虫系统**等采集数据
数据经过**ETL(数据清洗)**后进入**数据仓库**
狭义的ETL
广义的ETL
数据仓库内的数据最终用途有**报表系统、用户画像、推荐系统、机器学习、风控系统**

# 二、项目需求与架构设计

## 1.1 项目需求分析

### 项目需求
1. 数据**采集平台搭建**
2. 实现**用户行为数据仓库**的**分层搭建**
3. 实现**业务数据仓库**的分层搭建
4. 很对数据仓库中的数据进行**留存、转换率、GMV、复购率、活跃**等**报表分析**

>**留存**
用户留存，网站新增用户数除以访问量即为用户留存率
商品留存，下单总量除以访问量为商品留存率

>**转化率**
从某一渠道多少次访问后留存即为该渠道转化率

>**GMV(总成交额)**
已经付款的金额和未付款的金额总和

>**复购率**
用户在平台(对某个商品)重复购买频率

>**活跃**
用户活跃度，即用户停留时间，登录间隔

## 1.2 项目框架

### 1.2.1 技术选型

>**数据采集传输**
**Flume**，日志
**Kafka**，消息中间件
**Sqoop**，关系型数据库
Logstash，ELK套件类似FLume，在新的大数据公司有广泛引用
DataX，异构数据源同步工具，类似于Sqoop，但是比Sqoop功能强大
*DataX在国内应用广泛

>**数据存储**
**MySQL**
**HDFS**
HBase
Redis，用于缓存用于存放不敏感数据
MongoDB，文档型数据库，自描述数据
*HBase不利于查询，需要使用java代码编写filter，一般HBase和Pheonix搭配使用

>**数据计算**
**Hive**，离线计算
**Tez**，针对mr进行了优化，本质上不是mr模型，mr不支持DAG(有向无边图)，主要用于复杂业务(job之间存在复杂依赖关系)
**Spark**，准实时计算，hive on spark，使用Spark后hql不再转换成mr而是spark程序(内存计算)，速度更快,只有大企业才会使用Spark，小的企业使用Hive就能满足业务需求
Flink，国内有很强的上升趋势
Storm，真正的实时计算，生态环境差，不能通过yarn进行资源调度
*Tez和Spark同时通过yarn进行资源调度

>**数据查询**
**Presto**，
**Druid**，在Kylin的基础上加了时间线
Impala，CDH官方自带
Kylin，与原生Apache搭配使用

### 1.2.2 系统数据流程设计

![](img/sys-data-process-design.png)

 * *该图要能够做到手绘，并对每个细节进行叙述*

**高可扩**(双层Flume中间对接Kafka，可以扩展实时指标分析)
对于HDFS中的数据进行分层(ods、dwd、dws、ads)，使用Hive分析

### 1.2.3 框架版本选型

>**Apache**
运维麻烦、组件间兼容需要自己调研
一般时大的企业使用，技术实力雄厚，有专业的运维人员

>**CDH**
国内使用最多的版本，但CM不开源
对中小型企业的使用无影响(推荐使用)

>**HDP**
开源，可以进行二次开发，但是没有CDH稳定，国内使用较少

 * *CDH和HDP已经合并*

| Apache     | Version   |
| :--------- | :-------- |
| **Hadoop** | **2.7.2** |
| **Flume**  | **1.7.0** |
| Kafka      | 0.11.0.2  |
| **Hive**   | **1.2.1** |
| Sqoop      | 1.4.6     |
| MySQL      | 5.6.24    |
| Azkaban    | 2.5.0     |
| Java       | 1.8       |
| ZooKeeper  | 2.4.10    |
| Presto     | 0.189     |

| CDH        | Version   |
| :--------- | :-------- |
| **Hadoop** | **2.6.0** |
| **Spark**  | **1.6.0** |
| **Flume**  | **1.6.0** |
| **Hive**   | **1.1.0** |
| Sqoop      | 1.4.6     |
| Oozie      | 4.1.0     |
| ZooKeeper  | 3.4.5     |
| Impala     | 2.9.0     |

 * *框架选型尽量不要选最新的框架，选择最新框架前半年左右的稳定版。*

### 1.2.4 服务器选型

物理机和云主机的选择

>**机器成本考虑**
**物理机**，以128G内存，20核物理CPU，40线程，8THDD和2TSSD，戴尔品牌单台报价4W出头，需考虑托管服务器费用，一般物理机寿命为5年左右

**云主机**，以阿里云为例，差不多相同配置，每年5W

>**运维成本考虑**
**物理机**，需要有专业的运维人员
**云主机**，很多运维工作都由阿里云完成，运维轻松

### 1.2.5 集群资源规划设计

**集群规模的确定**
<!-- TODO 下述计算方式存疑 -->
每天日活用户为100万，没人每天平均100条数据，每条日志1K左右
则每天产生数据约为100G
半年内不扩容服务器，保存3个副本，需要54T容量
预留20~30%Buffer需要77T
所以集群的规模约为 8T*10台服务器
如果考虑到数仓分层，服务器将近扩容1-2倍

**测试集群服务器规划**
| 服务名称              | 子服务           | 服务器   hadoop102 | 服务器   hadoop103 | 服务器   hadoop104 |
| --------------------- | ---------------- | ------------------ | ------------------ | ------------------ |
| HDFS                  | NameNode         | √                  |                    |                    |
| DataNode              | √                | √                  | √                  |                    |
| SecondaryNameNode     |                  |                    | √                  |                    |
| Yarn                  | NodeManager      | √                  | √                  | √                  |
| Resourcemanager       |                  | √                  |                    |                    |
| Zookeeper             | Zookeeper Server | √                  | √                  | √                  |
| Flume(采集日志)       | Flume            | √                  | √                  |                    |
| Kafka                 | Kafka            | √                  | √                  | √                  |
| Flume（消费Kafka）    | Flume            |                    |                    | √                  |
| Hive                  | Hive             | √                  |                    |                    |
| MySQL                 | MySQL            | √                  |                    |                    |
| Sqoop                 | Sqoop            | √                  |                    |                    |
| Presto                | Coordinator      | √                  |                    |                    |
| Worker                |                  | √                  | √                  |                    |
| Azkaban               | AzkabanWebServer | √                  |                    |                    |
| AzkabanExecutorServer | √                |                    |                    |                    |
| Druid                 | Druid            | √                  | √                  | √                  |
| 服务数总计            |                  | 13                 | 8                  | 9                  |

>**规划原则**
占内存的进程分开
占磁盘IO的进程分开

# 三、数据生成模块

## 1.埋点数据基本格式

>**公共字段**
基本所有安卓手机都包含的字段

>**业务字段**
埋点上报的字段，有具体的业务类型

**埋点数据示例**
```json
{
    "ap": "xxxxx", //项目数据来源 app pc
    "cm": { //common 公共字段
        "mid": "", // (String) 设备唯一标识
        "uid": "", // (String) 用户标识
        "vc": "1", // (String) versionCode，程序版本号
        "vn": "1.0", // (String) versionName，程序版本名
        "l": "zh", // (String) language系统语言
        "sr": "", // (String) 渠道号，应用从哪个渠道来的。
        "os": "7.1.1", // (String) Android系统版本
        "ar": "CN", // (String) area区域
        "md": "BBB100-1", // (String) model手机型号
        "ba": "blackberry", // (String) brand手机品牌
        "sv": "V2.2.1", // (String) sdkVersion
        "g": "", // (String) gmail
        "hw": "1620x1080", // (String) heightXwidth，屏幕宽高
        "t": "1506047606608", // (String) 客户端日志产生时的时间
        "nw": "WIFI", // (String) 网络模式
        "ln": 0, // (double) lng经度
        "la": 0 // (double) lat 纬度
    },
    "et": [ //事件
        {
            "ett": "1506047605364", //客户端事件产生时间
            "en": "display", //事件名称
            "kv": { //事件结果，以key-value形式自行定义
                "goodsid": "236",
                "action": "1",
                "extend1": "1",
                "place": "2",
                "category": "75"
            }
        }
    ]
}
```
**示例日志**
```json
1540934156385|{ //时间戳|日志
    "ap": "gmall",
    "cm": {
        "uid": "1234",
        "vc": "2",
        "vn": "1.0",
        "la": "EN",
        "sr": "",
        "os": "7.1.1",
        "ar": "CN",
        "md": "BBB100-1",
        "ba": "blackberry",
        "sv": "V2.2.1",
        "g": "abc@gmail.com",
        "hw": "1620x1080",
        "t": "1506047606608",
        "nw": "WIFI",
        "ln": 0
    },
    "et": [
        {
            "ett": "1506047605364", //客户端事件产生时间
            "en": "display", //事件名称
            "kv": { //事件结果，以key-value形式自行定义
                "goodsid": "236",
                "action": "1",
                "extend1": "1",
                "place": "2",
                "category": "75"
            }
        },
        {
            "ett": "1552352626835",
            "en": "active_background",
            "kv": {
                "active_source": "1"
            }
        }
    ]
}
```

## 2.事件日志数据

### 2.1 商品列表页(loading)

| 标签         | 含义                                                                                          |
| ------------ | --------------------------------------------------------------------------------------------- |
| action       | 动作：开始加载=1，加载成功=2，加载失败=3                                                      |
| loading_time | 加载时长：计算下拉开始到接口返回数据的时间，（开始加载报0，加载成功或加载失败才上报时间）     |
| loading_way  | 加载类型：1-读取缓存，2-从接口拉新数据    （加载成功才上报加载类型）                          |
| extend1      | 扩展字段 Extend1                                                                              |
| extend2      | 扩展字段 Extend2                                                                              |
| type         | 加载类型：自动加载=1，用户下拽加载=2，底部加载=3（底部条触发点击底部提示条/点击返回顶部加载） |
| type1        | 加载失败码：把加载失败状态码报回来（报空为加载成功，没有失败）                                |

### 2.2 商品点击(display)

| 标签     | 含义                                               |
| -------- | -------------------------------------------------- |
| action   | 动作：曝光商品=1，点击商品=2，                     |
| goodsid  | 商品ID（服务端下发的ID）                           |
| place    | 顺序（第几条商品，第一条为0，第二条为1，如此类推） |
| extend1  | 曝光类型：1 - 首次曝光 2-重复曝光                  |
| category | 分类ID（服务端定义的分类ID）                       |

### 2.3 商品详情页(newsdetail)

| 标签          | 含义                                                                                                                                                                                                                   |
| ------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| entry         | 页面入口来源：应用首页=1、push=2、详情页相关推荐=3                                                                                                                                                                     |
| action        | 动作：开始加载=1，加载成功=2（pv），加载失败=3, 退出页面=4                                                                                                                                                             |
| goodsid       | 商品ID（服务端下发的ID）                                                                                                                                                                                               |
| show_style    | 商品样式：0、无图、1、一张大图、2、两张图、3、三张小图、4、一张小图、5、一张大图两张小图                                                                                                                               |
| news_staytime | 页面停留时长：从商品开始加载时开始计算，到用户关闭页面所用的时间。若中途用跳转到其它页面了，则暂停计时，待回到详情页时恢复计时。或中途划出的时间超过10分钟，则本次计时作废，不上报本次数据。如未加载成功退出，则报空。 |
| loading_time  | 加载时长：计算页面开始加载到接口返回数据的时间 （开始加载报0，加载成功或加载失败才上报时间）                                                                                                                           |
| type1         | 加载失败码：把加载失败状态码报回来（报空为加载成功，没有失败）                                                                                                                                                         |
| category      | 分类ID（服务端定义的分类ID）                                                                                                                                                                                           |

### 2.4 广告(ad)

| 标签       | 含义                                                                                                                                                                                                                    |
| ---------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| entry      | 入口：商品列表页=1  应用首页=2 商品详情页=3                                                                                                                                                                             |
| action     | 动作：请求广告=1 取缓存广告=2  广告位展示=3 广告展示=4 广告点击=5                                                                                                                                                       |
| content    | 状态：成功=1  失败=2                                                                                                                                                                                                    |
| detail     | 失败码（没有则上报空）                                                                                                                                                                                                  |
| source     | 广告来源:admob=1 facebook=2  ADX（百度）=3 VK（俄罗斯）=4                                                                                                                                                               |
| behavior   | 用户行为：    主动获取广告=1      被动获取广告=2                                                                                                                                                                        |
| newstype   | Type: 1-   图文 2-图集 3-段子 4-GIF 5-视频 6-调查 7-纯文 8-视频+图文  9-GIF+图文  0-其他                                                                                                                                |
| show_style | 内容样式：无图(纯文字)=6 一张大图=1  三站小图+文=4 一张小图=2 一张大图两张小图+文=3 图集+文 = 5     一张大图+文=11   GIF大图+文=12  视频(大图)+文 = 13    来源于详情页相关推荐的商品，上报样式都为0（因为都是左文右图） |

### 2.5 消息通知(notification)

| 标签    | 含义                                                                                     |
| ------- | ---------------------------------------------------------------------------------------- |
| action  | 动作：通知产生=1，通知弹出=2，通知点击=3，常驻通知展示（不重复上报，一天之内只报一次）=4 |
| type    | 通知id：预警通知=1，天气预报（早=2，晚=3），常驻=4                                       |
| ap_time | 客户端弹出时间                                                                           |
| content | 备用字段                                                                                 |

### 2.6 用户前台活跃(active_foreground)

| 标签    | 含义                                         |
| ------- | -------------------------------------------- |
| push_id | 推送的消息的id，如果不是从推送消息打开，传空 |
| access  | 1.push   2.icon 3.其他                       |

### 2.7 用户后台活跃(active_foreground)

| 标签          | 含义                                        |
| ------------- | ------------------------------------------- |
| active_source | 1=upgrade,2=download(下载),3=plugin_upgrade |

### 2.8 评论(comment)

| **序号** | **字段名称** | **字段描述**                              | **字段类型** | **长度** | **允许空** | **缺省值** |
| -------- | ------------ | ----------------------------------------- | ------------ | -------- | ---------- | ---------- |
| 1        | comment_id   | 评论表                                    | int          | 10,0     |            |            |
| 2        | userid       | 用户id                                    | int          | 10,0     | √          | 0          |
| 3        | p_comment_id | 父级评论id(为0则是一级评论,不为0则是回复) | int          | 10,0     | √          |            |
| 4        | content      | 评论内容                                  | string       | 1000     | √          |            |
| 5        | addtime      | 创建时间                                  | string       |          | √          |            |
| 6        | other_id     | 评论的相关id                              | int          | 10,0     | √          |            |
| 7        | praise_count | 点赞数量                                  | int          | 10,0     | √          | 0          |
| 8        | reply_count  | 回复数量                                  | int          | 10,0     | √          | 0          |

### 2.9 收藏(favorites)

| **序号** | **字段名称** | **字段描述** | **字段类型** | **长度** | **允许空** | **缺省值** |
| -------- | ------------ | ------------ | ------------ | -------- | ---------- | ---------- |
| 1        | id           | 主键         | int          | 10,0     |            |            |
| 2        | course_id    | 商品id       | int          | 10,0     | √          | 0          |
| 3        | userid       | 用户ID       | int          | 10,0     | √          | 0          |
| 4        | add_time     | 创建时间     | string       |          | √          |            |

### 2.10 点赞(praise)

| **序号** | **字段名称** | **字段描述**                                            | **字段类型** | **长度** | **允许空** | **缺省值** |
| -------- | ------------ | ------------------------------------------------------- | ------------ | -------- | ---------- | ---------- |
| 1        | id           | 主键id                                                  | int          | 10,0     |            |            |
| 2        | userid       | 用户id                                                  | int          | 10,0     | √          |            |
| 3        | target_id    | 点赞的对象id                                            | int          | 10,0     | √          |            |
| 4        | type         | 点赞类型 1问答点赞 2问答评论点赞 3 文章点赞数4 评论点赞 | int          | 10,0     | √          |            |
| 5        | add_time     | 添加时间                                                | string       |          | √          |            |

### 2.11 错误日志

| 标签        | 描述     |
| ----------- | -------- |
| errorDetail | 错误详情 |
| errorBrief  | 错误摘要 |

## 3.启动日志数据(start)

| 标签         | 含义                                                         |
| ------------ | ------------------------------------------------------------ |
| entry        | 入口： push=1，widget=2，icon=3，notification=4, lockscreen_widget =5 |
| open_ad_type | 开屏广告类型:  开屏原生广告=1, 开屏插屏广告=2                |
| action       | 状态：成功=1  失败=2                                         |
| loading_time | 加载时长：计算下拉开始到接口返回数据的时间，（开始加载报0，加载成功或加载失败才上报时间） |
| detail       | 失败码（没有则上报空）                                       |
| extend1      | 失败的message（没有则上报空）                                |
| en           | 日志类型start                                                |

```json
{
    "action": "1",
    "ar": "MX",
    "ba": "HTC",
    "detail": "",
    "en": "start",
    "entry": "2",
    "extend1": "",
    "g": "43R2SEQX@gmail.com",
    "hw": "640*960",
    "l": "en",
    "la": "20.4",
    "ln": "-99.3",
    "loading_time": "2",
    "md": "HTC-2",
    "mid": "995",
    "nw": "4G",
    "open_ad_type": "2",
    "os": "8.1.2",
    "sr": "B",
    "sv": "V2.0.6",
    "t": "1561472502444",
    "uid": "995",
    "vc": "10",
    "vn": "1.3.4"
}
```

## 4.数据生成脚本

* *见Maven工程log-collector*

# 四、数据采集模块

## 1.Hadoop安装配置

**集群规划**

|       |    服务器hadoop102     |       服务器hadoop103       |         服务器hadoop104         |
| :---: | :--------------------: | :-------------------------: | :-----------------------------: |
| HDFS  | NameNode <br> DataNode |          DataNode           | DataNode <br> SecondaryNameNode |
| YARN  |      NodeManager       | ResourceManager NodeManager |           NodeManager           |

[Hadoop集群配置步骤](link/steps.md)

### 1.1 HDFS存储多目录

当HDFS空间不足紧张时，我们需要对DataNode进行扩展，在hdfs-site.xml中添加以下配置
```xml
<property>
    <name>dfs.datanode.data.dir</name>
    <value>file:///${hadoop.tmp.dir}/dfs/data1,file:///hd2/dfs/data2,file:///hd3/dfs/data3,file:///hd4/dfs/data4</value>
</property>
```
### 1.2 支持LZO压缩配置 

hadoop本身并不支持lzo压缩，故需要使用twitter提供的hadoop-lzo开源组件。hadoop-lzo需依赖hadoop和lzo进行编译
[编译步骤 link/hadoop-lzo.md](link/hadoop-lzo.md)

**配置**
```bash
# 拷贝编译好的jar包到指定目录
cp hadoop-lzo-0.4.20.jar $HADOOP_HOME/share/hadoop/common/
# 分发
xsync $HADOOP_HOME/share/hadoop/common/hadoop-lzo-0.4.20.jar
vim core-site.xml
xsync core-site.xml # 分发
```
```xml
<?xml version="1.0" encoding="UTF-8" ?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl" ?>

<configuration>
    <property>
        <name>io.compression.codecs</name>
        <value>
            org.apache.hadoop.io.compress.GzipCodec,
            org.apache.hadoop.io.compress.DefaultCodec,
            org.apache.hadoop.io.compress.BZip2Codec,
            org.apache.hadoop.io.compress.SnappyCodec,
            com.hadoop.compression.lzo.LzoCodec,
            com.hadoop.compression.lzo.LzopCodec
        </value>
    </property>

    <property>
        <name>io.compression.codec.lzo.class</name>
        <value>com.hadoop.compression.lzo.LzoCodec</value>
    </property>
</configuration>
```
**测试**
<!-- TODO 压缩测试，需要big_file.lzo -->
```bash
# 启动集群
start-dfs.sh
start-yarn.sh
# 创建lzo文件的索引，lzo压缩文件的可切片特性依赖于其索引，
# 故我们需要手动为lzo压缩文件创建索引。
# 若无索引，则lzo文件的切片只有一个。
hadoop jar share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer big_file.lzo
```
```sql
--（1）hive建表语句
create table testLZO(id bigint, time bigint, uid string, keyword string, url_rank int, click_num int, click_url string) row format delimited fields terminated by '\t' STORED AS
INPUTFORMAT 'com.hadoop.mapred.DeprecatedLzoTextInputFormat'
OUTPUTFORMAT 'org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat';
--（2）向表中导入数据，bigtable.lzo大小为140M
load data local inpath '/opt/module/datas/bigtable.lzo' into table bigtable;
--（3）测试（建索引之前），观察map个数（1个）
select id,count(*) from bigtable group by id limit 10;
--（4）建索引
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /user/hive/warehouse/bigtable
--（5）测试（建索引之后），观察map个数（2个）
select id,count(*) from bigtable group by id limit 10;
```
### 1.3 基准测试
<!-- TODO 待验证... -->
**测试写性能**
```bash
# 向HDFS集群写10个128M的文件
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -write -nrFiles 10 -fileSize 128MB
```
[写性能日志](link/test-write.log)

**测试读性能**
```bash
# 读取HDFS集群10个128M的文件
mapreduce]$ hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -read -nrFiles 10 -fileSize 128MB
```
[读性能日志](link/test-read.log)

**测试删除生成数据**
```bash
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-2.7.2-tests.jar TestDFSIO -clean
```
**使用sort程序评测MapReduce**
```bash
# 使用RandomWriter来产生随机数，每个节点运行10个Map任务，每个Map产生大于1G大小的二进制数
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar randomwriter random-data
# 执行sort程序
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar sort random-data sorted-data
# 验证数据是否真正排序
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar testmapredsort -sortInput random-data -sortOutput sorted-data
```


### 1.4 Hadoop参数调优

#### 1.4.1 HDFS参数调优hdfs-site.xml
1. dfs.namenode.handler.count=20 * log2(Cluster Size)，比如集群规模为8台时，此参数设置为60
```
The number of Namenode RPC server threads that listen to requests from clients. 
If dfs.namenode.servicerpc-address is not configured 
then Namenode RPC server threads listen to requests from all nodes.
NameNode有一个工作线程池，用来处理不同DataNode的并发心跳以及客户端并发的元数据操作。
对于大集群或者有大量客户端的集群来说，通常需要增大参数dfs.namenode.handler.count的默认值10。
设置该值的一般原则是将其设置为集群大小的自然对数乘以20，即20logN，N为集群大小。
```
2. 编辑日志存储路径dfs.namenode.edits.dir设置与镜像文件存储路径dfs.namenode.name.dir尽量分开，达到最低写入延迟

#### 1.4.2 Yarn参数调优yarn-site.xml
>**情景描述**
总共7台机器，每天几亿条数据，数据源->Flume->Kafka->HDFS->Hive
面临问题：数据统计主要用HiveSQL，没有数据倾斜，小文件已经做了合并处理，开启的JVM重用，而且IO没有阻塞，内存用了不到50%。但是还是跑的非常慢，而且数据量洪峰过来时，整个集群都会宕掉。基于这种情况有没有优化方案。

>**解决办法**
内存利用率不够一般是Yarn的2个配置造成的，单个任务可以申请的最大内存大小，和Hadoop单个节点可用内存大小。调节者连个参数能提高系统内存的利用率
`yarn.nodemanager.resource.memory-mb`表示该节点上yarn可用的物理内存总量，默认是8192(MB)，注意，如果你的节点内存资源不够8GB，则需要调减小这个值，而YARN不会智能的探测节点的物理内存总量。
`yarn.scheduler.maximum-allocation-mb`单个任务可申请的最多物理内存量，默认是8192(MB)


#### 1.4.3 Hadoop宕机
1. 如果MR造成系统宕机。此时要控制Yarn同时运行的任务数，和每个任务申请的最大内存。
   调整参数`yarn.scheduler.maximum-allocation-mb`单个任务可申请的最多物理内存量，默认时8192MB
2. 如果写入文件过量造成NameNode宕机。那么调高Kafka的存储大小，控制从Kafka到HDFS的写入速度。
   高峰期的时候用Kafka进行缓存，高峰期过去数据同步会自动跟上。

## 2.ZooKeeper安装配置

### 2.1 集群规划

|               | hadoop102 | hadoop103 | hadoop104 |
| :------------ | :-------- | :-------- | :-------- |
| **ZooKeeper** | ZooKeeper | ZooKeeper | ZooKeeper |

[ZooKeeper集群配置步骤](link/steps.md)

### 2.2 ZK集群启停脚本

[zk集群启停脚本](../ShellScript/zk.sh)

### 2.3 Linux环境变量

```bash
vim ~/.bashrc # 每个节点添加 source /etc/profile
```

## 3.日志生成

```bash
# module下常见jar文件夹,并把生成数据的脚本jar包上传，分发
mkdir jar
scp *.jar hadoop102:/opt/module/jar # powershell端上传至服务器
xsync /opt/module/jar/ # 分发
# hadoop102节点执行程序
java -classpath log-collector-1.0-SNAPSHOT-jar-with-dependencies.jar com.tian.appclient.AppMain  >/opt/gmall/logs/test.log
tail 10 /opt/module/datas/test.log # 查看生成的数据
ll /tmp/logs/ # 查看生成的日志文件
# app-2019-08-22.log
```

[集群日志生成启动脚本](../ShellScript/lg.sh)
[集群时间同步修改脚本](../ShellScript/dt.sh)
[集群所有进程查看脚本](../ShellScript/xcall.sh)
## 4.采集日志Flume

### 4.1 Flume安装部署
[Flume安装部署](link/steps.md)

**集群规划**

|                 | 服务器hadoop102 | 服务器hadoop103 | 服务器hadoop104 |
| --------------- | --------------- | --------------- | --------------- |
| Flume(采集日志) | Flume           | Flume           |                 |

### 4.2 Flume组件

#### 4.2.1 Source
>**Taildir Source**
TailDir Source：断点续传、多目录。Flume1.6以前需要自己自定义Source记录每次读取文件位置，实现断点续传。
Exec Source可以实时搜集数据，但是在Flume不运行或者Shell命令出错的情况下，数据将会丢失。
Spooling Directory Source监控目录，不支持断点续传。

>**batchSize**
Event 1K左右时，500-1000合适（默认为100）

#### 4.2.2 Channel
采用Kafka Channel，省去了sink提高了效率

### 4.3 Flume配置文件
<!-- TODO 添加Flume配置分析配图 -->
![]()
Flume直接读log日志的数据，log日志的格式是app-yyyy-mm-dd.log
[Flume配置文件](../Configuration/Flume/File-Flume-Kafka.conf)

* com.tian.flume.interceptor.LogETLInterceptor和com.tian.flume.interceptor.LogTypeInterceptor是自定义的拦截器的全类名。
* 需要根据用户自定义的拦截器做相应修改。

### 4.4 Flume的ETL的分类型拦截器
本项目中自定义了两个拦截器，分别是：ETL拦截器、日志类型区分拦截器。
ETL拦截器主要用于，过滤时间戳不合法和Json数据不完整的日志
日志类型区分拦截器主要用于，将启动日志和事件日志区分开来，方便发往Kafka的不同Topic。

* 拦截器见Maven工程文件 flume-interceptor
* 打包为jar后放入到hadoop102的/opt/module/flume/lib并分发
  

[日志采集Flume启停脚本](../ShellScript/f1.sh)

## 5.Kafka部署

### 5.1 Kafka安装配置

[Kafka安装部署](link/steps.md)

**集群规划**
|       | 服务器hadoop102 | 服务器hadoop103 | 服务器hadoop104 |
| ----- | --------------- | --------------- | --------------- |
| Kafka | Kafka           | Kafka           | Kafka           |

[Kafka启停脚本](../ShellScript/kf.sh)

### 5.2 Kafka Topic操作
<!-- TODO ▲添加测试操作 -->

### 5.3 Kafka压力测试


### 5.4 Kafka及其数量计算

$Kafka机器数量（经验公式）=2*（峰值生产速度*副本数/压测写入速度）+1$

先要预估一天大概产生多少数据，然后用Kafka自带的生产压测（只测试Kafka的写入速度，保证数据不积压），计算出峰值生产速度。再根据设定的副本数，就能预估出需要部署Kafka的数量。

比如我们采用压力测试测出写入的速度是10M/s一台，峰值的业务数据的速度是50M/s。副本数为2。

$Kafka机器数量=2*（50*2/100）+ 1=3台$

## 6.消费Kafka数据Flume

### 6.1 Flume配置
**集群规划**
|                    | 服务器hadoop102 | 服务器hadoop103 | 服务器hadoop104 |
| ------------------ | --------------- | --------------- | --------------- |
| Flume（消费Kafka） |                 |                 | Flume           |

[Flume配置文件](../Configuration/Flume/File-Flume-hdfs.conf)
[消费Kafka数据Flume启停脚本](../ShellScript/f2.sh)

### 6.2 Flume内存优化

>**启动消费Flume抛出如下异常**
```
ERROR hdfs.HDFSEventSink: process failed
java.lang.OutOfMemoryError: GC overhead limit exceeded
```

>**解决方案**
在`/opt/module/flume/conf/flume-env.sh`中添加配置export `JAVA_OPTS="-Xms100m -Xmx2000m -Dcom.sun.management.jmxremote"`并分发到其他节点

>**Flume内存参数设置及优化**
`JVM heap`一般设置为4G或更高，部署在单独的服务器上(4核8线程16G内存)
`-Xmx`与`-Xms`最好设置一致，减少内存抖动带来的性能影响，如果设置不一致容易导致频繁fullgc

### 6.3 Flume组件

#### 6.3.1 FileChannel和MemoryChannel区别
MemoryChannel传输数据速度更快，但因为数据保存在JVM的堆内存中，Agent进程挂掉会导致数据丢失，适用于对数据质量要求不高的需求。
FileChannel传输速度相对于Memory慢，但数据安全保障高，Agent进程挂掉也可以从失败中恢复数据。

#### 6.3.2 FileChannel优化
通过配置dataDirs指向多个路径，每个路径对应不同的硬盘，增大Flume吞吐量。
官方说明:`Comma separated list of directories for storing log files. Using multiple directories on separate disks can improve file channel peformance`
`checkpointDir`和`backupCheckpointDir`也尽量配置在不同硬盘对应的目录中，保证checkpoint坏掉后，可以快速使用`backupCheckpointDir`恢复数据

#### 6.3.3 Sink：HDFS Sink
>**HDFS中存入大量小文件的影响**
**元数据层面**：每个小文件都有一份元数据，其中包括文件路径，文件名，所有者，所属组，权限，创建时间等，这些信息都保存在Namenode内存中。所以小文件过多，会占用Namenode服务器大量内存，影响Namenode性能和使用寿命
**计算层面**：默认情况下MR会对每个小文件启用一个Map任务计算，非常影响计算性能。同时也影响磁盘寻址时间。

>**小文件处理**
官方默认的这三个参数配置写入HDFS后会产生小文件，`hdfs.rollInterval`、`hdfs.rollSize`、`hdfs.rollCount`
基于以上`hdfs.rollInterval=3600`，`hdfs.rollSize=134217728`，`hdfs.rollCount =0`，`hdfs.roundValue=10`，`hdfs.roundUnit= second`
几个参数综合作用，效果如下：
tmp文件在达到128M时会滚动生成正式文件
tmp文件创建超3600秒时会滚动生成正式文件
举例：在2018-01-01 05:23的时侯sink接收到数据，那会产生如下tmp文件：
/tian/20180101/tian.201801010620.tmp
即使文件内容没有达到128M，也会在06:23时滚动生成正式文件


## 7.采集通道启停脚本
 * 把系统时间更改为过去时间用户采集过去数据时需要重启集群
 * 若是更改为未来时间并采集未来时间的数据则无影响
[采集通道启停脚本](../ShellScript/cluster.sh)

# 五、总结

## 1.数仓概念总结

### 数据仓库的输入数据源和输出系统
**输入系统**:埋点产生的用户行为数据，JavaEE后台产生的业务数据
**输出系统**:报表系统、用户画像系统、推荐系统

## 2.项目需求即架构总结

### 2.1 集群规模计算

### 2.2 框架版本选型


### 2.3 服务器选型


## 3.数据采集模块总结

### 3.1 Linux & Shell

| Command                       | Description                       |
| :---------------------------- | :-------------------------------- |
| top                           | 查看内存                          |
| df -h                         | 查看磁盘存储情况                  |
| iotop                         | 查看磁盘IO读写(yum install iotop) |
| iotop -o                      | 查看比较高的磁盘读写程序          |
| netstat -tunlp \| grep [Port] | 查看端口查看端口占用情况          |
| uptime                        | 查看报告系统运行时长及平均负载    |
| ps aux                        | 查看进程                          |

* Shell常用工具 awk sed cut sort

### 3.2 Hadoop

1. Hadoop默认不支持LZO压缩，业务有需要则手动添加jar包并在core-site.xml中添加配置
2. Hadoop常用端口号
3. Hadoop配置文件以及简单的Hadoop集群搭建
4. HDFS读流程和写流程
5. MapReduce和Shuffle过程及Hadoop优化(压缩、小文件、集群优化)
6. Yarn的job提交流程
7. Yarn的默认调度器、调度器分类、以及他们之间的区别
8. HDFS存储多目录
9. Hadoop参数调优
10. 基准测试

### 3.3 ZooKeeper

* **选举机制**:半数机制
* 常用命令:ls get create

### 3.4 Flume
<!-- TODO 添加Flume总结 -->

### 3.4 Kafka
<!-- 添加Kafka架构配图 -->

1. Kafka压测
   Kafka官方自带压力测试脚本(`kafka-consumer-perf-test.sh`、`kafka-producer-perf-test.sh`)。Kafka压测时，可以查看到哪个地方出现了瓶颈（CPU，内存，网络IO）。一般都是网络IO达到瓶颈。
2. Kafka机器数量为$2*(峰值生产速度*副本数/压测写入速度)+1$
3. Kafka日志保存时间为7天
4. Kafka硬盘大小为$每天的数据量*7天$
5. Kafka监控，公司自己开发的监视器，开源的监控器(KafkaManager、KafkaMonitor)
6. Kafka分区数
   分区数并不是越多越好，一般分区数不要超过集群机器数量。分区数越多占用内存越大（ISR等），一个节点集中的分区也就越多，当它宕机的时候，对系统的影响也就越大。分区数一般设置为3~10个
7. 副本数设置，一般我们设置成2个或者3个，很多企业设置为2个
8. Topic个数通常与日志类型一致，也有对日志类型进行合并的
9.  Kafka数据安全性
    ```
    Ack=0，相当于异步发送，消息发送完毕即offset增加，继续生产。
    Ack=1，leader收到leader replica 对一个消息的接受ack才增加offset，然后继续生产。
    Ack=-1，leader收到所有replica 对一个消息的接受ack才增加offset，然后继续生产。
    ```

10. Kafka的ISR副本同步队列
    ISR（In-Sync Replicas），副本同步队列。ISR中包括Leader和Follower。如果Leader进程挂掉，会在ISR队列中选择一个服务作为新的Leader。有`replica.lag.max.messages`（延迟条数）和`replica.lag.time.max.ms`（延迟时间）两个参数决定一台服务是否可以加入ISR副本队列，在0.10版本移除了`replica.lag.max.messages`参数，防止服务频繁的进去队列。
    任意一个维度超过阈值都会把Follower剔除出ISR，存入OSR（Outof-Sync Replicas）列表，新加入的Follower也会先存放在OSR中。
11. Kafka分区分配策略
    在 Kafka内部存在两种默认的分区分配策略：Range和 RoundRobin。
    Range是默认策略。Range是对每个Topic而言的（即一个Topic一个Topic分），首先对同一个Topic里面的分区按照序号进行排序，并对消费者按照字母顺序进行排序。然后用Partitions分区的个数除以消费者线程的总数来决定每个消费者线程消费几个分区。如果除不尽，那么前面几个消费者线程将会多消费一个分区。
    例如：我们有10个分区，两个消费者（C1，C2），3个消费者线程，10 / 3 = 3而且除不尽
    
    ```
    C1-0 将消费 0, 1, 2, 3 分区
    C2-0 将消费 4, 5, 6 分区
    C2-1 将消费 7, 8, 9 分区
    ```
    * RoundRobin：前提：同一个Consumer Group里面的所有消费者的num.streams（消费者消费线程数）必须相等；每个消费者订阅的主题必须相同。将所有主题分区组成TopicAndPartition列表，然后对TopicAndPartition列表按照hashCode进行排序，最后按照轮询的方式发给每一个消费线程。
12. Kafka中数据量的计算
    ```
    每天总数据量100g，每天产生1亿条日志， 10000万/24/60/60=1150条/每秒钟
    平均每秒钟：1150条
    低谷每秒钟：400条
    高峰每秒钟：1150条*（2-20倍）=2300条-23000条
    每条日志大小：0.5k-2k
    每秒多少数据量：2.3M-20MB
    ```
13. Kafka挂掉
    ```
    Flume记录
    日志有记录
    短期没事
    ```
14. Kafka消息数据积压，Kafka消费能力不足解决方法
    * 如果是Kafka消费能力不足，则可以考虑增加Topic的分区数，并且同时提升消费组的消费者数量，消费者数=分区数。（两者缺一不可）
    * 如果是下游的数据处理不及时：提高每批次拉取的数量。批次拉取数据过少（拉取数据/处理时间<生产速度），使处理的数据小于生产的数据，也会造成数据积压。


