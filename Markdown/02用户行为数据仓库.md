# 一、数仓分层

## 1.概念

### 1.1 分层原因

>**复杂问题简单化**
将一个复杂的**任务分解**成多个步骤，每层只处理单一的步骤，**比较简单，方便定位问题**

>**减少重复开发**
规范数据分层，通过的**中间层数据**，能够减少极大的重复计算，增加一次计算结果的复用性

>**隔离原始数据**
不论是数据的异常还是数据的敏感性，使真是数据与统计数据**解耦**开

### 1.2 数仓分层

>**ODS层(原始数据层)**
存放原始数据，直接加载原始日志、数据，数据保持原貌不作处理

>**DWD层(明细数据层)**
结构和粒度与原始表保持一致，**ODS层数据进行清洗(去除空值、脏数据、超过极限范围的数据)**，个别公司称为DWI

>**DWS层(服务数据层)**
以DWD为基础，**进行数据轻度汇总**，一般聚集到以用户当日、设备当日、商家当日、商品当日等等的粒度
通常会有以某个维度为线索，组成跨主题的宽表，比如，一个用户的当日的签到数、收藏数、评论数、抽奖数、订阅数、点赞数、流浪商品数、添加购物车数、下单数、支持数、退款数7点击广告数组成的列表

>**ADS层(数据应用层)**
**为各种统计报表提供数据**，也有称为APP层、DM等

## 2.数据集市和数据仓库

**数据集市(Data Market)**是一种**微型的数据仓库**，通常有更少的数据，更少的主题区域，以及更少的历史数据，因此是**部门级**的，一般只能为某个局部范围内的管理人员服务
**数据仓库**是**企业级**的，能为整个企业各个部门的运行提供决策支持手段
 * 数据集市现在市面上的公司和书籍对数据集市有不同的概念

## 3.数仓命名规范

 * ODS层 --- ods
 * DWD层 --- dwd
 * DWS层 --- dws
 * ADS层 --- ads
 * 临时表数据库命名为 xxx-tmp
 * 备份数据数据库命名为 xxx_bak


# 二、数仓搭建环境准备

**集群规划**
|       | hadoop102 | hadoop103 | hadoop104 |
| :---- | :-------- | :-------- | :-------- |
| Hive  | Hive      |           |           |
| MySQL | MySQL     |           |           |

## 1.Hive & MySQL

[安装配置步骤](link/steps.md)

```bash
# 关闭元数据检查
vim /opt/module/hive/conf/hive-site.xml
```
```xml
<property>
    <name>hive.metastore.schema.verification</name>
    <value>false</value>
</property>
```

## 2.Hive引擎Tez
Tez是一个Hive的运行引擎，性能优于MR。为什么优于MR呢？看下图。
<!-- TODO Tez配图 -->
![]()
用Hive直接编写MR程序，假设有四个有依赖关系的MR作业，上图中，绿色是Reduce Task，云状表示写屏蔽，需要将中间结果持久化写到HDFS。
Tez可以将多个有依赖的作业转换为一个作业，这样只需写一次HDFS，且中间节点较少，从而大大提升作业的计算性能。

### 2.1 安装配置

[Tez安装配置上传测试](link/steps.md)

### 2.2 问题总结

>**运行Tez检查到用过多内存而被NodeManager杀死进程**
Caused by: org.apache.tez.dag.api.SessionNotRunning: TezSession has already shutdown. Application application_1546781144082_0005 failed 2 times due to AM Container for appattempt_1546781144082_0005_000002 exited with  exitCode: -103
For more detailed output, check application tracking page:http://hadoop103:8088/cluster/app/application_1546781144082_0005Then, click on links to logs of each attempt.
Diagnostics: Container [pid=11116,containerID=container_1546781144082_0005_02_000001] is running beyond virtual memory limits. Current usage: 216.3 MB of 1 GB physical memory used; 2.6 GB of 2.1 GB virtual memory used. Killing container.

>**问题原因:从机上运行的Container试图使用过多的内存，而被NodeManager kill掉了**
The NodeManager is killing your container. It sounds like you are trying to use hadoop streaming which is running as a child process of the map-reduce task. The NodeManager monitors the entire process tree of the task and if it eats up more memory than the maximum set in mapreduce.map.memory.mb or mapreduce.reduce.memory.mb respectively, we would expect the Nodemanager to kill the task, otherwise your task is stealing memory belonging to other containers, which you don't want.

>**解决方法，修改yarn-site.xml重启集群**
```xml
<property>
    <name>yarn.nodemanager.vmem-check-enabled</name>
    <value>false</value>
</property>
```

## 3.元数据备份

元数据备份（重点，如数据损坏，可能整个集群无法运行，至少要保证每日零点之后备份到其它服务器两个复本）
<!-- TODO ... -->

# 三、ODS层搭建
 * 原始数据层，存放原始数据，直接加载原始日志、数据，数据保持原貌不作处理

<!-- TODO ODS层表分析图 -->
[HQL脚本](../Database/hql/ods.hql)

```bash
# 为lzo文件创建索引
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /warehouse/gmall/ods/ods_start_log/dt=2019-08-24
hadoop jar /opt/module/hadoop-2.7.2/share/hadoop/common/hadoop-lzo-0.4.20.jar com.hadoop.compression.lzo.DistributedLzoIndexer /warehouse/gmall/ods/ods_event_log/dt=2019-08-24
```
[ODS层加载数据脚本](../ShellScript/ods_log.sh)

# 四、DWD层搭建
 * 对ODS层数据进行清洗（去除空值，脏数据，超过极限范围的数据，行式存储改为列存储，改压缩格式）。
## 1.启动表数据解析
<!-- TODO 启动表分析 -->
[HQL脚本](../Database/hql/dwd_start.hql)

[ODS层加载数据脚本](../ShellScript/dwd_start_log.sh)

## 2.事件表数据解析
### 2.1 创建事件表
<!-- TODO 事件表分析 -->
[HQL脚本](../Database/hql/dwd_base.hql)


### 2.2 自定义UDF函数
 * 解析共同字段
 * 自定义UDF函数见见Maven工程文件 hivefunction

### 2.3 自定义UDTF函数
 * 解体具体事件字段

[DWD层数据解析脚本](../ShellScript/dwd_base_log.sh)

 * 自定义UDTF函数见见Maven工程文件 hivefunction


```bash
# 上传jar包到hdfs
hadoop fs -mkdir /user/hive/jars
hadoop fs -put hivefunction-1.0-SNAPSHOT-jar-with-dependencies.jar /user/hive/jars
hadoop fs -put hivefunction-1.0-SNAPSHOT.jar /user/hive/jars
```
```sql
-- 创建永久函数与jar包关联
create function base_analizer 
as 'com.tian.udf.BaseFieldUDF' 
using jar 'hdfs://hadoop102:9000/user/hive/jars/hivefunction-1.0-SNAPSHOT.jar';

create function flat_analizer 
as 'com.tian.udtf.EventJsonUDTF' 
using jar 'hdfs://hadoop102:9000/user/hive/jars/hivefunction-1.0-SNAPSHOT.jar'; 
```
## 3.事件表获取

[HQL脚本](../Database/hql/dwd_event.hql)

[DWD层数据解析脚本](../ShellScript/dwd_event_log.sh)

# 五、业务知识准备
## 1.业务术语

>**用户**
用户以设备为判断标准，在移动统计中，每个独立设备认为是一个独立用户。Android系统根据IMEI号，IOS系统根据OpenUDID来标识一个独立用户，每部手机一个用户。

>**新增用户**
首次联网使用应用的用户。如果一个用户首次打开某APP，那这个用户定义为新增用户；卸载再安装的设备，不会被算作一次新增。新增用户包括日新增用户、周新增用户、月新增用户。

>**活跃用户**
打开应用的用户即为活跃用户，不考虑用户的使用情况。每天一台设备打开多次会被计为一个活跃用户。

>**周(月)活跃用户**
某个自然周（月）内启动过应用的用户，该周（月）内的多次启动只记一个活跃用户。

>**月活跃率**
月活跃用户与截止到该月累计的用户总和之间的比例。

>**沉默用户**
用户仅在安装当天（次日）启动一次，后续时间无再启动行为。该指标可以反映新增用户质量和用户与APP的匹配程度。

>**版本分布**
不同版本的周内各天新增用户数，活跃用户数和启动次数。利于判断APP各个版本之间的优劣和用户行为习惯。

>**本周回流用户**
上周未启动过应用，本周启动了应用的用户。

>**连续n周活跃用户**
连续n周，每周至少启动一次。

>**忠诚用户**
连续活跃5周以上的用户

>**连续活跃用户**
连续2周及以上活跃的用户

>**近期流失用户**
连续n(2<= n <= 4)周没有启动应用的用户。（第n+1周没有启动过）

>**留存用户**
某段时间内的新增用户，经过一段时间后，仍然使用应用的被认作是留存用户；这部分用户占当时新增用户的比例即是留存率。
例如，5月份新增用户200，这200人在6月份启动过应用的有100人，7月份启动过应用的有80人，8月份启动过应用的有50人；则5月份新增用户一个月后的留存率是50%，二个月后的留存率是40%，三个月后的留存率是25%。


>**用户新鲜度**
每天启动应用的新老用户比例，即新增用户数占活跃用户数的比例。

>**单次使用时长**
每次启动使用的时间长度。

>**日使用时长**
累计一天内的使用时间长度。

>**启动次数计算标准**
IOS平台应用退到后台就算一次独立的启动；Android平台我们规定，两次启动之间的间隔小于30秒，被计算一次启动。用户在使用过程中，若因收发短信或接电话等退出应用30秒又再次返回应用中，那这两次行为应该是延续而非独立的，所以可以被算作一次使用行为，即一次启动。业内大多使用30秒这个标准，但用户还是可以自定义此时间间隔。

## 2.系统函数

### 2.1 collect_set函数
```sql
-- 1）创建原数据表 
hive (gmall)>
drop table if exists stud;
create table stud (name string, area string, course string, score int);
-- 2）向原数据表中插入数据 
hive (gmall)>
insert into table stud values('zhang3','bj','math',88);
insert into table stud values('li4','bj','math',99);
insert into table stud values('wang5','sh','chinese',92);
insert into table stud values('zhao6','sh','chinese',54);
insert into table stud values('tian7','bj','chinese',91);
-- 3）查询表中数据 
hive (gmall)> select * from stud;
stud.name       stud.area       stud.course     stud.score
zhang3 bj      math    88
li4     bj      math    99
wang5   sh      chinese 92
zhao6   sh      chinese 54
tian7   bj      chinese 91
-- 4）把同一分组的不同行的数据聚合成一个集合  
hive (gmall)> select course, collect_set(area), avg(score) from stud group by course;
chinese ["sh","bj"]     79.0
math    ["bj"]  93.5
-- 5） 用下标可以取某一个 
hive (gmall)> select course, collect_set(area)[0], avg(score) from stud group by course;
chinese sh      79.0
math    bj      93.5
```
### 2.2 日期处理函数
```sql
-- 1）date_format函数（根据格式整理日期） 
hive (gmall)> select date_format('2019-02-10','yyyy-MM');
2019-02
-- 2）date_add函数（加减日期） 
hive (gmall)> select date_add('2019-02-10',-1);
2019-02-09
hive (gmall)> select date_add('2019-02-10',1);
2019-02-11
-- 3）next_day函数 
-- （1）取当前天的下一个周一
hive (gmall)> select next_day('2019-02-12','MO');
2019-02-18
-- 说明：星期一到星期日的英文（Monday，Tuesday、Wednesday、Thursday、Friday、Saturday、Sunday） 
-- （2）取当前周的周一 
hive (gmall)> select date_add(next_day('2019-02-12','MO'),-7);
2019-02-11
-- 4）last_day函数（求当月最后一天日期） 
hive (gmall)> select last_day('2019-02-10');
2019-02-28
```

# 六、用户需求

## 1.用户活跃主题

## 2.用户新增主题

## 3.用户留存主题

## 4.沉默用户数

## 5.本周回流用户数

## 6.流失用户数


## 7.最近连续三周活跃用户数


## 8.最近七天连续三天活跃用户数


# 七、总结

## 1.用户行为数仓业务总结

## 2.Hive总结

